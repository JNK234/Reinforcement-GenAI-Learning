# NotebookLM Resource Guide - Direct Links for Knowledge Forging

> ðŸ“š **Optimized for NotebookLM**: Each topic includes direct PDF/video links that can be uploaded to NotebookLM for interactive learning sessions

## How to Use with NotebookLM

1. **Upload Strategy**:
   - Upload 2-3 related PDFs/transcripts per NotebookLM notebook
   - Group by specific topic (e.g., "MDPs", "Q-Learning")
   - Include one theoretical + one practical resource

2. **Knowledge Forging Process**:
   - Upload materials to NotebookLM
   - Use the chat to ask clarifying questions
   - Generate summaries and study guides
   - Export refined notes to your Zettelkasten

---

## Topic-Specific Resources with Direct Links

### 1. Markov Decision Processes (MDPs)

#### Primary Materials for NotebookLM:
- **CS234 Lecture 2 Slides**: [Download PDF](https://web.stanford.edu/class/cs234/slides/cs234_lecture2.pdf)
- **CS285 Fall 2023 Lecture 2**: [Download PDF](https://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-2.pdf)
- **Sutton & Barto Chapter 3**: [Download PDF](http://incompleteideas.net/book/RLbook2020.pdf#page=65)
- **David Silver Lecture 2**: [Download PDF](https://www.davidsilver.uk/wp-content/uploads/2020/03/MDP.pdf)

#### Video Transcripts (get from YouTube):
- CS234 Lecture 2: https://www.youtube.com/watch?v=E3f2Camj0Is
- David Silver MDP: https://www.youtube.com/watch?v=lfHX2hHRMVQ

#### NotebookLM Session Ideas:
- "Explain the Bellman equation with examples"
- "Compare deterministic vs stochastic MDPs"
- "How do MDPs apply to business decisions?"

### 2. Dynamic Programming

#### Primary Materials for NotebookLM:
- **CS234 Lecture 3 Slides**: [Download PDF](https://web.stanford.edu/class/cs234/slides/cs234_lecture3.pdf)
- **CS285 Lecture 3**: [Download PDF](https://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-3.pdf)
- **Sutton & Barto Chapter 4**: [Download PDF](http://incompleteideas.net/book/RLbook2020.pdf#page=89)
- **Bertsekas DP Book Sample**: [Chapter 1 PDF](http://www.athenasc.com/dpchapter.pdf)

#### Video Resources:
- MIT Dynamic Programming: https://ocw.mit.edu/courses/6-231-dynamic-programming-and-stochastic-control-fall-2015/

#### NotebookLM Session Ideas:
- "Explain value iteration vs policy iteration"
- "When is DP practical vs impractical?"

### 3. Q-Learning & Temporal Difference

#### Primary Materials for NotebookLM:
- **CS234 Lecture 4-5**: [Download PDF](https://web.stanford.edu/class/cs234/slides/cs234_lecture4.pdf)
- **CS285 TD Learning**: [Download PDF](https://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-5.pdf)
- **Original Q-Learning Paper**: [Download PDF](https://link.springer.com/content/pdf/10.1007/BF00992698.pdf)
- **Sutton & Barto Ch 6-7**: [Download PDF](http://incompleteideas.net/book/RLbook2020.pdf#page=129)

#### NotebookLM Session Ideas:
- "Compare Q-learning, SARSA, and Expected SARSA"
- "Explain convergence guarantees"

### 4. Deep Q-Networks (DQN)

#### Primary Materials for NotebookLM:
- **CS285 DQN Lecture**: [Download PDF](https://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-7.pdf)
- **Original DQN Paper**: [arXiv PDF](https://arxiv.org/pdf/1312.5602.pdf)
- **Nature DQN Paper**: [Download](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)
- **Rainbow DQN**: [arXiv PDF](https://arxiv.org/pdf/1710.02298.pdf)

#### Implementation Guides:
- **DQN Explained**: https://huggingface.co/blog/deep-rl-dqn
- **37 Implementation Details**: https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/

### 5. Policy Gradient Methods

#### Primary Materials for NotebookLM:
- **CS285 Policy Gradients**: [Download PDF](https://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-4.pdf)
- **CS234 Lecture 7**: [Download PDF](https://web.stanford.edu/class/cs234/slides/cs234_lecture7.pdf)
- **Sutton PG Paper**: [Download PDF](https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf)
- **John Schulman Thesis**: [Download PDF](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-217.pdf)

#### NotebookLM Session Ideas:
- "Derive the policy gradient theorem"
- "Explain variance reduction techniques"

### 6. Actor-Critic & PPO

#### Primary Materials for NotebookLM:
- **CS285 Actor-Critic**: [Download PDF](https://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-5.pdf)
- **PPO Paper**: [arXiv PDF](https://arxiv.org/pdf/1707.06347.pdf)
- **TRPO Paper**: [arXiv PDF](https://arxiv.org/pdf/1502.05477.pdf)
- **SAC Paper**: [arXiv PDF](https://arxiv.org/pdf/1801.01290.pdf)

### 7. Transformers & Attention

#### Primary Materials for NotebookLM:
- **Attention Paper**: [arXiv PDF](https://arxiv.org/pdf/1706.03762.pdf)
- **The Annotated Transformer**: [Download](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
- **CS224n Transformers**: [Download PDF](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes06-NMT_seq2seq_attention.pdf)
- **Illustrated Transformer**: Convert to PDF from https://jalammar.github.io/illustrated-transformer/

#### Video Transcripts:
- Karpathy's Let's Build GPT: https://www.youtube.com/watch?v=kCc8FmEb1nY

### 8. Language Model Training

#### Primary Materials for NotebookLM:
- **GPT-3 Paper**: [arXiv PDF](https://arxiv.org/pdf/2005.14165.pdf)
- **Scaling Laws Paper**: [arXiv PDF](https://arxiv.org/pdf/2001.08361.pdf)
- **Chinchilla Paper**: [arXiv PDF](https://arxiv.org/pdf/2203.15556.pdf)
- **Training Compute-Optimal LLMs**: [Download](https://www.deepmind.com/publications/training-compute-optimal-large-language-models)

### 9. RLHF & Alignment

#### Primary Materials for NotebookLM:
- **InstructGPT Paper**: [arXiv PDF](https://arxiv.org/pdf/2203.02155.pdf)
- **Constitutional AI**: [arXiv PDF](https://arxiv.org/pdf/2212.08073.pdf)
- **RLHF Blog Post**: [Convert to PDF](https://huggingface.co/blog/rlhf)
- **DPO Paper**: [arXiv PDF](https://arxiv.org/pdf/2305.18290.pdf)

### 10. Mathematical Foundations

#### Optimization:
- **Boyd Convex Optimization Ch 1-3**: [Download PDF](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf)
- **Gradient Descent Overview**: [Download PDF](https://www.cs.cmu.edu/~ggordon/10725-F12/slides/05-gd-revisited.pdf)

#### Probability for RL:
- **Concentration Inequalities**: [Download PDF](https://www.cs.columbia.edu/~djhsu/papers/chernoff_hoeffding.pdf)
- **Bandits Book Ch 1-3**: [Download PDF](https://tor-lattimore.com/downloads/book/book.pdf)

---

## NotebookLM Workflow for Each Topic

### Stage 1: Initial Upload (Per Topic)
1. Upload 2-3 core PDFs
2. Add any video transcripts
3. Include one implementation guide

### Stage 2: Knowledge Forging Questions

#### For Conceptual Understanding:
- "What are the 5 key concepts in these materials?"
- "Explain [concept] in simple terms with an example"
- "What assumptions does this method make?"
- "Compare and contrast [method A] vs [method B]"

#### For Mathematical Understanding:
- "Walk through the derivation of [equation]"
- "What does each term in this equation represent?"
- "Under what conditions does this converge?"

#### For Implementation:
- "What are the key implementation details?"
- "What are common pitfalls when implementing this?"
- "Generate pseudocode for the core algorithm"

#### For Business/Management Perspective:
- "How would you explain this to a non-technical executive?"
- "What are real-world applications?"
- "What are the costs and benefits?"

### Stage 3: Synthesis & Export
1. Ask NotebookLM to create a comprehensive summary
2. Generate study guide with key points
3. Create practice questions
4. Export to your note system

---

## Organizing NotebookLM Notebooks

### Suggested Notebook Structure:
```
ðŸ“ RL Foundations
  ðŸ““ MDPs and Dynamic Programming
  ðŸ““ Value-Based Methods (Q-Learning, DQN)
  ðŸ““ Policy-Based Methods (PG, PPO)
  
ðŸ“ Deep RL
  ðŸ““ Function Approximation
  ðŸ““ Actor-Critic Methods
  ðŸ““ Advanced Topics (MBRL, Offline RL)
  
ðŸ“ Generative AI
  ðŸ““ Transformer Architecture
  ðŸ““ LLM Training and Scaling
  ðŸ““ Alignment and Safety
  
ðŸ“ Mathematics
  ðŸ““ Optimization for ML
  ðŸ““ Probability and Statistics
  ðŸ““ Linear Algebra Refresher
```

### Tips for NotebookLM Success:

1. **Quality over Quantity**: 2-3 highly relevant PDFs > 10 loosely related ones
2. **Mix Theory and Practice**: Always include both conceptual and implementation resources
3. **Progressive Learning**: Start with foundations before advanced topics
4. **Cross-Reference**: Create notebooks that bridge topics
5. **Regular Reviews**: Revisit notebooks to reinforce learning

---

## Quick Reference: Best Single PDFs per Topic

If you can only upload ONE PDF per topic to NotebookLM:

1. **MDPs**: Sutton & Barto Chapter 3
2. **Q-Learning**: CS234 Lecture 4-5 combined slides  
3. **DQN**: Nature DQN Paper
4. **Policy Gradients**: John Schulman's thesis Chapter 3
5. **PPO**: Original PPO paper
6. **Transformers**: Attention is All You Need
7. **LLM Training**: Scaling Laws paper
8. **RLHF**: InstructGPT paper
9. **Math/Optimization**: Boyd Chapter 1-3

---

## Creating Your Knowledge Base

After each NotebookLM session:
1. Export key insights to Obsidian
2. Create atomic notes for each concept
3. Link related concepts
4. Add your own examples and insights
5. Create a "manager view" and "scientist view" for each topic
6. Draft blog post outlines while knowledge is fresh

Remember: NotebookLM is your interactive tutor. Use it to clarify doubts immediately, just as the Knowledge Forging technique suggests!